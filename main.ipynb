{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "main.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python [conda env:deep_learning]",
   "language": "python",
   "name": "conda-env-deep_learning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "nzopYfHLOmLF",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1618862522233,
     "user_tz": -120,
     "elapsed": 19645,
     "user": {
      "displayName": "Marco Bronzini",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgP_C6dW3BlgojpPSXptMFbaA1Idmql190WUFTDgA=s64",
      "userId": "13323167468298286112"
     }
    },
    "outputId": "cc266c78-0526-445f-c6f2-8cb547b24eb3"
   },
   "source": [
    "# for domonkos to run on COLAB\n",
    "\n",
    "import os\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "os.chdir('/content/drive/MyDrive/python/Computer_Vision/TDT4265_Project/')"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9xu4cyaaVcLK",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1618862522564,
     "user_tz": -120,
     "elapsed": 19961,
     "user": {
      "displayName": "Marco Bronzini",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgP_C6dW3BlgojpPSXptMFbaA1Idmql190WUFTDgA=s64",
      "userId": "13323167468298286112"
     }
    }
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "3KcwLfCBOLxw",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1618862530864,
     "user_tz": -120,
     "elapsed": 28252,
     "user": {
      "displayName": "Marco Bronzini",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgP_C6dW3BlgojpPSXptMFbaA1Idmql190WUFTDgA=s64",
      "userId": "13323167468298286112"
     }
    }
   },
   "source": [
    "from src.data import load_train_test_val, load_tee\n",
    "from src.visualize import plot_loss_acc\n",
    "from src.model import Unet2D\n",
    "#from src.baseline_model import Unet2D\n",
    "from src.train import train\n",
    "from src.utils import save_result, to_cuda\n",
    "from src.test import test\n",
    "from src.metrics import acc_metric\n",
    "from datetime import datetime\n",
    "\n",
    "from params import *\n",
    "\n",
    "import torch\n",
    "from torch import nn"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lTckNYRZOLxy"
   },
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "u6uNX1mfOLxy",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1618862546808,
     "user_tz": -120,
     "elapsed": 44189,
     "user": {
      "displayName": "Marco Bronzini",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgP_C6dW3BlgojpPSXptMFbaA1Idmql190WUFTDgA=s64",
      "userId": "13323167468298286112"
     }
    },
    "outputId": "d524e76c-c8af-4a1f-eb73-5981115b2ef7"
   },
   "source": [
    "train_data, test_data, valid_data = load_train_test_val(DATA_PARAMS, PREP_STEPS, TRAIN_TRANSFORMS)"
   ],
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "DATASET: extracted_CAMUS\n",
      "\n",
      "Items loaded: 1800 [training: 1600, test: 100, valid: 100]\n",
      "RAW IMAGES: torch.Size([8, 1, 384, 384])\n",
      " GT IMAGES: torch.Size([8, 384, 384])\n",
      "\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cpa1uwI5OLxz"
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "aO8NYIXZBsVj",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1618862546810,
     "user_tz": -120,
     "elapsed": 44181,
     "user": {
      "displayName": "Marco Bronzini",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgP_C6dW3BlgojpPSXptMFbaA1Idmql190WUFTDgA=s64",
      "userId": "13323167468298286112"
     }
    },
    "outputId": "38f36d94-16e8-44c9-9cff-9dbe48588fff"
   },
   "source": [
    "# MODEL: Unet2D (one input channel, 4 output channels)\n",
    "unet = Unet2D(1, out_channels=4)\n",
    "print(unet)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.Adam(unet.parameters(), lr=LEARN_RATE)"
   ],
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Unet2D(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Dropout2d(p=0.1, inplace=False)\n",
      "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Dropout2d(p=0.1, inplace=False)\n",
      "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv3): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Dropout2d(p=0.1, inplace=False)\n",
      "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv4): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Dropout2d(p=0.1, inplace=False)\n",
      "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv5): Sequential(\n",
      "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Dropout2d(p=0.1, inplace=False)\n",
      "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (upconv5): Sequential(\n",
      "    (0): ConvTranspose2d(512, 512, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Dropout2d(p=0.1, inplace=False)\n",
      "  )\n",
      "  (upconv4): Sequential(\n",
      "    (0): ConvTranspose2d(512, 512, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (1): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Dropout2d(p=0.1, inplace=False)\n",
      "  )\n",
      "  (upconv3): Sequential(\n",
      "    (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (1): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Dropout2d(p=0.1, inplace=False)\n",
      "  )\n",
      "  (upconv2): Sequential(\n",
      "    (0): ConvTranspose2d(128, 128, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Dropout2d(p=0.1, inplace=False)\n",
      "  )\n",
      "  (upconv1): Sequential(\n",
      "    (0): ConvTranspose2d(64, 64, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Dropout2d(p=0.1, inplace=False)\n",
      "    (8): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (9): Softmax(dim=1)\n",
      "  )\n",
      ")\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "aCk3CSKZBsVk",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "375ed2e1-ddfd-4818-ad04-291bb7337550"
   },
   "source": [
    "if LOAD: # Load pretrained model\n",
    "    unet.load_state_dict(torch.load(MODEL_PATH+FILE_NAME))\n",
    "    to_cuda(unet)\n",
    "    print(f\"The pre-trained model'{FILE_NAME}' has been loaded\")\n",
    "else:  # Start the training process\n",
    "    start = datetime.now()\n",
    "    train_loss, test_loss, train_acc, test_acc = train(unet, train_data, test_data, loss_fn, opt, acc_metric, epochs=EPOCHS)\n",
    "\n",
    "    end = datetime.now()\n",
    "    print(f\"Elapsed time is {str(end-start)}\")"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "----------\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "hnk3-CuQsYHs",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "if not LOAD:\n",
    "    plot_loss_acc(train_loss, test_loss, train_acc, test_acc)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j0-5OTiPOLx0"
   },
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "rtSGt_bFBsVm"
   },
   "source": [
    "print(\"TEST on the CAMUS dataset\")\n",
    "accuracy, average_dice, class_dice = test(unet, valid_data, True)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7QTRMOWHNyGB"
   },
   "source": [
    "print(f\"Test on TEE images\")\n",
    "tee_data = load_tee(DATA_PARAMS['base_path'], DATA_PARAMS['batch_size'])\n",
    "accuracy_tee, average_dice_tee, class_dice_tee = test(unet, tee_data, True)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y5OCjb85s-ww"
   },
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "x_KkUAoyOLx0"
   },
   "source": [
    "if not LOAD:\n",
    "  # save the result\n",
    "  msg = 'Test the saving function'\n",
    "\n",
    "  file_name = 'Gauss_bringth_scale15_model'\n",
    "\n",
    "  # Save the model\n",
    "  save_result(unet, file_name, accuracy_tee, average_dice_tee, class_dice_tee, msg = msg)\n",
    "else:\n",
    "  print(\"The model was already trained\")"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}